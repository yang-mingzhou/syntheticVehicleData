{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continuous-cedar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 12:16:13.922 | calibration.py:38 | WARNING: No module named 'pymoo'\n",
      "Try running `pip install pymoo==0.6.0.1` to use all features in `fastsim.calibration`\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import matplotlib.dates as mdates\n",
    "import sumolib\n",
    "import osmnx as ox\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import logging\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "from fastsim import simdrive, vehicle, cycle\n",
    "from fastsim import parameters as params\n",
    "\n",
    "import traci\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import utils.simulation as sim \n",
    "from utils.featureExtraction import feature_extraction\n",
    "# postprocessing to edge level\n",
    "from utils.postprocessing import process_edge_gdf, process_one_file, edge_list_to_node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "attempted-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_trips = 2\n",
    "\n",
    "data_file_folder = \"data\"\n",
    "results_file_folder = \"results\"\n",
    "\n",
    "edge_level_data_folder = os.path.join(data_file_folder, \"processed/synthetic\")\n",
    "results_data_file_folder = os.path.join(data_file_folder, \"features/synthetic\")\n",
    "\n",
    "os.makedirs(edge_level_data_folder, exist_ok=True)  # Create the destination folder if it doesn't exist\n",
    "os.makedirs(results_data_file_folder, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "earlier-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SUMO_HOME; revise it according to the path to the site-packages folder of SUMO  \n",
    "os.environ['PATH'] += \":/home/shekhars/yang7492/.conda/envs/syntheticData/lib/python3.8/site-packages/sumo/bin\"\n",
    "os.environ['SUMO_HOME'] = '/home/shekhars/yang7492/.conda/envs/syntheticData/lib/python3.8/site-packages/sumo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "north-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load openstreet map:\n",
    "osm_file_path = os.path.join(data_file_folder, \"maps/minneapolis.graphml\")\n",
    "osmnx_net = ox.io.load_graphml(osm_file_path)\n",
    "node_gdf, edge_gdf = ox.utils_graph.graph_to_gdfs(osmnx_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adjusted-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sumo map:\n",
    "net_file = os.path.join(data_file_folder, \"Minneapolis.net.xml\")\n",
    "sumo_net = sumolib.net.readNet(net_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "renewable-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMO simulation configuration\n",
    "# file name for random O-D pairs\n",
    "od_file = os.path.join(data_file_folder, \"incompelete_routes.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coral-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file name for complete routes\n",
    "complete_route_file = os.path.join(data_file_folder, \"complete_routes.rou.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "motivated-fabric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command executed successfully\n",
      "Output: Success.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim.construct_complete_route(os.environ['SUMO_HOME'], number_of_trips, number_of_trips, net_file, od_file, complete_route_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "affiliated-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.add_speed_attributes_to_vehicles(complete_route_file, \"0.00\", \"0.00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "endless-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_ids = [f\"t{i}\" for i in range(number_of_trips)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "quarterly-ontario",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      "Step #2972.00 (0ms ?*RT. ?UPS, TraCI: 0ms, vehicles TOT 2 ACT 0 BUF 0)                    \n"
     ]
    }
   ],
   "source": [
    "begin = 0\n",
    "end = 14400 # maximum simulated travel time \n",
    "step_length = 1\n",
    "file_name_config = \"sumo.sumocfg\"\n",
    "sim.save_sumo_config_to_file(net_file, complete_route_file, begin, end, step_length, file_name_config)\n",
    "\n",
    "# sumo simulation\n",
    "velocity_data, edgeSeq_data = sim.sumo_simulation(file_name_config, vehicle_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "separate-motivation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(velocity_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "alternative-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic vehicle type\n",
    "# 62 predefined vehicle types in FASTSim: https://github.com/NREL/fastsim/blob/fastsim-2/python/fastsim/resources/FASTSim_py_veh_db.csv\n",
    "# vehicle_type = np.random.randint(1, 27, number_of_trips)\n",
    "# vehicle_type = 0 -> the predefined Murphy Heavey Duty Truck. Refer to cumstomize_veh() in simultation.py\n",
    "vehicle_type = [0 for _ in range(number_of_trips)]\n",
    "\n",
    "# generte a dataframe of the synthetic data based on SUMO results\n",
    "csv_file = sim.generate_synthetic_csv(velocity_data, edgeSeq_data, vehicle_type, edge_gdf, sumo_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "domestic-jonathan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_start_time</th>\n",
       "      <th>trip_end_time</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>velocity_profile</th>\n",
       "      <th>weight</th>\n",
       "      <th>total_fuel</th>\n",
       "      <th>ambTemperature</th>\n",
       "      <th>trajectory</th>\n",
       "      <th>matched_path</th>\n",
       "      <th>coordinate_id</th>\n",
       "      <th>road_id</th>\n",
       "      <th>vehicle_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-12 21:00:58.125121</td>\n",
       "      <td>2023-09-12 21:13:23.125121</td>\n",
       "      <td>745</td>\n",
       "      <td>[0.0, 2.1255339903524146, 3.8917453708825636, ...</td>\n",
       "      <td>[1782.4383835997862]</td>\n",
       "      <td>[52.647826746482316]</td>\n",
       "      <td>8</td>\n",
       "      <td>[(44.78809, -93.462495)]</td>\n",
       "      <td>[(187912911, 187912915, 0), (187912911, 187912...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[(187912911, 187912915, 0), (187912911, 187912...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-03 07:34:21.125132</td>\n",
       "      <td>2023-04-03 08:23:47.125132</td>\n",
       "      <td>2966</td>\n",
       "      <td>[0.0, 2.3753579159732907, 4.265551309264265, 6...</td>\n",
       "      <td>[1901.753956859937]</td>\n",
       "      <td>[95.8902504937399]</td>\n",
       "      <td>8</td>\n",
       "      <td>[(44.78809, -93.462495)]</td>\n",
       "      <td>[(34385365, 33314213, 0), (34385365, 33314213,...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[(34385365, 33314213, 0), (34385365, 33314213,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             trip_start_time              trip_end_time  travel_time  \\\n",
       "0 2023-09-12 21:00:58.125121 2023-09-12 21:13:23.125121          745   \n",
       "1 2023-04-03 07:34:21.125132 2023-04-03 08:23:47.125132         2966   \n",
       "\n",
       "                                    velocity_profile                weight  \\\n",
       "0  [0.0, 2.1255339903524146, 3.8917453708825636, ...  [1782.4383835997862]   \n",
       "1  [0.0, 2.3753579159732907, 4.265551309264265, 6...   [1901.753956859937]   \n",
       "\n",
       "             total_fuel  ambTemperature                trajectory  \\\n",
       "0  [52.647826746482316]               8  [(44.78809, -93.462495)]   \n",
       "1    [95.8902504937399]               8  [(44.78809, -93.462495)]   \n",
       "\n",
       "                                        matched_path coordinate_id  \\\n",
       "0  [(187912911, 187912915, 0), (187912911, 187912...           [0]   \n",
       "1  [(34385365, 33314213, 0), (34385365, 33314213,...           [0]   \n",
       "\n",
       "                                             road_id  vehicle_type  \n",
       "0  [(187912911, 187912915, 0), (187912911, 187912...             0  \n",
       "1  [(34385365, 33314213, 0), (34385365, 33314213,...             0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "first-cigarette",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 13:20:45.181 | simdrive.py:2280 | WARNING: trace miss distance fraction 0.07968 exceeds tolerance of 0.001\n",
      "2024-03-28 13:20:45.182 | simdrive.py:2298 | WARNING: trace miss speed 12.79396 m/s exceeds tolerance of 1.0 m/s\n",
      "2024-03-28 13:20:45.551 | simdrive.py:2280 | WARNING: trace miss distance fraction 0.04532 exceeds tolerance of 0.001\n",
      "2024-03-28 13:20:45.552 | simdrive.py:2298 | WARNING: trace miss speed 16.87919 m/s exceeds tolerance of 1.0 m/s\n"
     ]
    }
   ],
   "source": [
    "# Process the data (trip level) and save to the destination folder\n",
    "simulated_data = sim.fastsim(csv_file, velocity_data, edgeSeq_data, data_file_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "forced-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert space-separated strings to lists of floats\n",
    "float_list_columns = ['fastsim_velocity', 'fastsim_power', 'sumo_velocity']\n",
    "for column in float_list_columns:\n",
    "    simulated_data[column] = simulated_data[column].apply(lambda x: [float(i) for i in x.split()])\n",
    "\n",
    "# Convert space-separated strings to lists\n",
    "simulated_data['sumo_path'] = simulated_data['sumo_path'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dietary-perth",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# conver the processed data to edge level\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m edge_gdf \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_edge_gdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_gdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_gdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_file_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_edge \u001b[38;5;241m=\u001b[39m process_one_file(simulated_data, edge_gdf, sumo_net)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Save the processed DataFrame to a new CSV in the output folder\u001b[39;00m\n",
      "File \u001b[0;32m/panfs/jay/groups/21/shekhars/yang7492/syntheticVehicleData/utils/postprocessing.py:162\u001b[0m, in \u001b[0;36mprocess_edge_gdf\u001b[0;34m(edge_gdf, node_gdf, results_file_folder)\u001b[0m\n\u001b[1;32m    159\u001b[0m edge_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignal_v_value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m edge_gdf\u001b[38;5;241m.\u001b[39msignal_v\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: endpoints_dictionary[x])\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# add edge_gdf['elevation_change']\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m edge_gdf \u001b[38;5;241m=\u001b[39m \u001b[43madd_elevation_change_to_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_gdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_gdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_gdf\n",
      "File \u001b[0;32m/panfs/jay/groups/21/shekhars/yang7492/syntheticVehicleData/utils/postprocessing.py:104\u001b[0m, in \u001b[0;36madd_elevation_change_to_edges\u001b[0;34m(nodes, edges)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_elevation_change_to_edges\u001b[39m(nodes, edges):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Extract locations from nodes for elevation fetching\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     locations \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m nodes\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Fetch elevations in batches and create a dictionary mapping node ID to elevation\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m  \u001b[38;5;66;03m# Adjust based on API limits\u001b[39;00m\n",
      "File \u001b[0;32m/panfs/jay/groups/21/shekhars/yang7492/syntheticVehicleData/utils/postprocessing.py:104\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_elevation_change_to_edges\u001b[39m(nodes, edges):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Extract locations from nodes for elevation fetching\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     locations \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m nodes\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Fetch elevations in batches and create a dictionary mapping node ID to elevation\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m  \u001b[38;5;66;03m# Adjust based on API limits\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/syntheticData/lib/python3.8/site-packages/pandas/core/frame.py:1400\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1398\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m-> 1400\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[1;32m   1402\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/geopandas/geodataframe.py:1640\u001b[0m, in \u001b[0;36mGeoDataFrame._constructor_sliced.<locals>._geodataframe_constructor_sliced\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_geodataframe_constructor_sliced\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;124;03m    A specialized (Geo)Series constructor which can fall back to a\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;124;03m    Series if a certain operation does not produce geometries:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;124;03m      checking the identity of the index)\u001b[39;00m\n\u001b[1;32m   1639\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1640\u001b[0m     srs \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1641\u001b[0m     is_row_proxy \u001b[38;5;241m=\u001b[39m srs\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_geometry_type(srs) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_row_proxy:\n",
      "File \u001b[0;32m~/.conda/envs/syntheticData/lib/python3.8/site-packages/pandas/core/series.py:422\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, SingleBlockManager) \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m copy:\n\u001b[1;32m    420\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 422\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[43mibase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_extract_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    425\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/.conda/envs/syntheticData/lib/python3.8/site-packages/pandas/core/indexes/base.py:7177\u001b[0m, in \u001b[0;36mmaybe_extract_name\u001b[0;34m(name, obj, cls)\u001b[0m\n\u001b[1;32m   7174\u001b[0m     name \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m   7176\u001b[0m \u001b[38;5;66;03m# GH#29069\u001b[39;00m\n\u001b[0;32m-> 7177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   7178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.name must be a hashable type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m name\n",
      "File \u001b[0;32m~/.conda/envs/syntheticData/lib/python3.8/site-packages/pandas/core/dtypes/inference.py:360\u001b[0m, in \u001b[0;36mis_hashable\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# Unfortunately, we can't use isinstance(obj, collections.abc.Hashable),\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# which can be faster than calling hash. That is because numpy scalars\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# fail this test.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# Reconsider this decision once this numpy bug is fixed:\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# https://github.com/numpy/numpy/issues/5562\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28mhash\u001b[39m(obj)\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# conver the processed data to edge level\n",
    "edge_gdf = process_edge_gdf(edge_gdf, node_gdf, results_file_folder)\n",
    "df_edge = process_one_file(simulated_data, edge_gdf, sumo_net)\n",
    "# Save the processed DataFrame to a new CSV in the output folder\n",
    "edge_level_output_file_name = os.path.join(edge_level_data_folder, \"synthetic.csv\")\n",
    "df_edge.to_csv(edge_level_output_file_name, index=False)\n",
    "print(f\"Saved processed data to {edge_level_output_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sweet-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_level_file_pattern = os.path.join(edge_level_data_folder, \"*.csv\")\n",
    "synthetic_data_flg = True\n",
    "feature_extraction(data_file_folder, results_file_folder, edge_level_file_pattern, results_data_file_folder, synthetic_data_flg)\n",
    "print(f\"Saved extracted feature data to {results_data_file_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-march",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-judgment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syntheticDataGen",
   "language": "python",
   "name": "syntheticdata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
